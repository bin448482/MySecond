"""
å¢å¼ºç‰ˆçŸ­çº¿é€‰è‚¡å·¥å…·ä¸»ç¨‹åº
é›†æˆåŠ¨æ€å»¶è¿Ÿã€æŒ‡æ•°é€€é¿ã€ç½‘ç»œçŠ¶æ€ç›‘æ§ç­‰åŠŸèƒ½
æä¾›æ›´ç¨³å®šçš„æ•°æ®è·å–å’Œæ–­ç‚¹ç»­ä¼ æœºåˆ¶
"""

import argparse
import sys
import time
import json
import os
from datetime import datetime, timedelta
from typing import Optional, List
import logging
import pandas as pd

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from database import DatabaseManager
from enhanced_data_fetcher import EnhancedDataFetcher, NetworkStatus
from utils import config_manager, logger


class EnhancedStockSelectorApp:
    """å¢å¼ºç‰ˆçŸ­çº¿é€‰è‚¡å·¥å…·ä¸»åº”ç”¨ç±»"""
    
    def __init__(self, enterprise_mode: bool = False):
        """åˆå§‹åŒ–åº”ç”¨"""
        self.config = config_manager
        self.db = DatabaseManager()
        self.data_fetcher = EnhancedDataFetcher(self.db, enterprise_mode=enterprise_mode)
        self.enterprise_mode = enterprise_mode
        
        mode_info = "ä¼ä¸šç½‘ç»œæ¨¡å¼" if enterprise_mode else "æ ‡å‡†æ¨¡å¼"
        logger.info(f"å¢å¼ºç‰ˆçŸ­çº¿é€‰è‚¡å·¥å…·åˆå§‹åŒ–å®Œæˆ - {mode_info}")
    
    def update_all_stocks_historical_data_enhanced(self, days: int = 60, resume: bool = True) -> dict:
        """
        å¢å¼ºç‰ˆæ‰¹é‡æ›´æ–°æ‰€æœ‰è‚¡ç¥¨å†å²æ•°æ®
        æ”¯æŒåŠ¨æ€å»¶è¿Ÿã€ç½‘ç»œçŠ¶æ€ç›‘æ§ã€æ™ºèƒ½æš‚åœç­‰åŠŸèƒ½
        
        Args:
            days: å†å²æ•°æ®å¤©æ•°
            resume: æ˜¯å¦ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­
            
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        progress_file = "data/enhanced_batch_progress.json"
        logger.info(f"å¼€å§‹å¢å¼ºç‰ˆæ‰¹é‡æ›´æ–°æ‰€æœ‰è‚¡ç¥¨è¿‘{days}å¤©çš„å†å²æ•°æ®...")
        
        try:
            # è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨
            stock_list = self.db.get_stock_list()
            if stock_list.empty:
                logger.error("æ²¡æœ‰è‚¡ç¥¨åˆ—è¡¨ï¼Œè¯·å…ˆæ›´æ–°è‚¡ç¥¨åˆ—è¡¨")
                return {}
            
            total_stocks = len(stock_list)
            all_symbols = stock_list['symbol'].tolist()
            
            # åŠ è½½ä¹‹å‰çš„è¿›åº¦
            progress_data = {}
            start_index = 0
            
            if resume:
                progress_data = self.load_enhanced_progress(progress_file)
                if progress_data:
                    start_index = progress_data.get('last_processed_index', -1) + 1
                    logger.info(f"æ£€æµ‹åˆ°ä¹‹å‰çš„è¿›åº¦ï¼Œä»ç¬¬ {start_index + 1} åªè‚¡ç¥¨ç»§ç»­å¤„ç†")
                    logger.info(f"ä¹‹å‰å·²å¤„ç†: {progress_data.get('success_count', 0)} æˆåŠŸ, {progress_data.get('failed_count', 0)} å¤±è´¥")
            
            # åˆå§‹åŒ–è¿›åº¦æ•°æ®
            if not progress_data:
                progress_data = {
                    'total_stocks': total_stocks,
                    'success_count': 0,
                    'failed_count': 0,
                    'total_records': 0,
                    'last_processed_index': -1,
                    'failed_symbols': [],
                    'paused_symbols': [],  # å› ç½‘ç»œé—®é¢˜æš‚åœçš„è‚¡ç¥¨
                    'start_time': datetime.now().isoformat(),
                    'days': days,
                    'network_pauses': 0,  # ç½‘ç»œæš‚åœæ¬¡æ•°
                    'total_pause_time': 0.0  # æ€»æš‚åœæ—¶é—´
                }
            
            symbols_to_process = all_symbols[start_index:]
            logger.info(f"æ€»è‚¡ç¥¨æ•°: {total_stocks:,}, å¾…å¤„ç†: {len(symbols_to_process):,}")
            
            total_start_time = time.time()
            last_network_check = time.time()
            
            # é€åªè‚¡ç¥¨å¤„ç†
            for i, symbol in enumerate(symbols_to_process):
                current_index = start_index + i
                
                # æ£€æŸ¥ç½‘ç»œçŠ¶æ€ï¼ˆæ¯50åªè‚¡ç¥¨æ£€æŸ¥ä¸€æ¬¡ï¼‰
                if i > 0 and i % 50 == 0:
                    network_status = self.data_fetcher.delay_manager.get_network_status()
                    metrics = self.data_fetcher.get_metrics_summary()
                    
                    logger.info(f"ç½‘ç»œçŠ¶æ€æ£€æŸ¥ - çŠ¶æ€: {network_status.value}, æˆåŠŸç‡: {metrics['success_rate']}")
                    
                    # å¦‚æœç½‘ç»œçŠ¶æ€å¾ˆå·®ï¼Œæš‚åœä¸€æ®µæ—¶é—´
                    if network_status == NetworkStatus.BAD:
                        pause_time = 60  # æš‚åœ1åˆ†é’Ÿ
                        logger.warning(f"ç½‘ç»œçŠ¶æ€å·®ï¼Œæš‚åœ {pause_time} ç§’...")
                        time.sleep(pause_time)
                        progress_data['network_pauses'] += 1
                        progress_data['total_pause_time'] += pause_time
                
                logger.info(f"å¤„ç†è‚¡ç¥¨ {current_index + 1}/{total_stocks}: {symbol}")
                
                # æ›´æ–°å•åªè‚¡ç¥¨çš„å†å²æ•°æ®
                try:
                    updated_count = self.data_fetcher.update_stock_data_with_fixed_delay(symbol, days)
                    
                    if updated_count > 0:
                        progress_data['success_count'] += 1
                        progress_data['total_records'] += updated_count
                        logger.info(f"  âœ… æˆåŠŸæ›´æ–° {updated_count} æ¡è®°å½•")
                    else:
                        # æ£€æŸ¥æ˜¯å¦å› ä¸ºç½‘ç»œé—®é¢˜å¤±è´¥
                        if self.data_fetcher.delay_manager.should_pause():
                            progress_data['paused_symbols'].append(symbol)
                            logger.warning(f"  â¸ï¸ å› ç½‘ç»œé—®é¢˜æš‚åœ")
                        else:
                            progress_data['failed_count'] += 1
                            progress_data['failed_symbols'].append(symbol)
                            logger.warning(f"  âŒ æ›´æ–°å¤±è´¥")
                    
                except Exception as e:
                    progress_data['failed_count'] += 1
                    progress_data['failed_symbols'].append(symbol)
                    logger.error(f"  âŒ æ›´æ–°å¤±è´¥: {e}")
                    logger.error(f"  è¯¦ç»†é”™è¯¯ä¿¡æ¯: {type(e).__name__}: {str(e)}")
                    # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯å †æ ˆ
                    import traceback
                    logger.error(f"  é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                
                # æ›´æ–°è¿›åº¦
                progress_data['last_processed_index'] = current_index
                progress_data['last_update'] = datetime.now().isoformat()
                
                # æ·»åŠ ç½‘ç»œæŒ‡æ ‡åˆ°è¿›åº¦æ•°æ®
                metrics = self.data_fetcher.get_metrics_summary()
                progress_data['current_network_status'] = metrics['network_status']
                progress_data['current_success_rate'] = metrics['success_rate']
                
                # æ¯å¤„ç†10åªè‚¡ç¥¨ä¿å­˜ä¸€æ¬¡è¿›åº¦
                if (i + 1) % 10 == 0:
                    self.save_enhanced_progress(progress_data, progress_file)
                
                # æ˜¾ç¤ºè¿›åº¦
                processed_count = current_index + 1
                progress_pct = (processed_count / total_stocks) * 100
                elapsed_time = time.time() - total_start_time
                
                if processed_count > start_index:
                    avg_time_per_stock = elapsed_time / (processed_count - start_index)
                    remaining_stocks = total_stocks - processed_count
                    eta_seconds = remaining_stocks * avg_time_per_stock
                    
                    if (i + 1) % 10 == 0:  # æ¯10åªè‚¡ç¥¨æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                        logger.info(f"è¿›åº¦: {progress_pct:.1f}% ({processed_count}/{total_stocks}) | "
                                   f"æˆåŠŸ: {progress_data['success_count']} | å¤±è´¥: {progress_data['failed_count']} | "
                                   f"æš‚åœ: {len(progress_data['paused_symbols'])} | "
                                   f"è®°å½•æ•°: {progress_data['total_records']:,} | "
                                   f"ç½‘ç»œ: {metrics['network_status']} | "
                                   f"é¢„è®¡å‰©ä½™: {eta_seconds/60:.1f}åˆ†é’Ÿ")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦å› ç½‘ç»œé—®é¢˜é•¿æ—¶é—´æš‚åœ
                if self.data_fetcher.delay_manager.should_pause():
                    logger.warning("ç½‘ç»œçŠ¶æ€æŒç»­ä¸ä½³ï¼Œå»ºè®®æš‚åœæ‰¹å¤„ç†")
                    logger.info("æ‚¨å¯ä»¥ç¨åé‡æ–°è¿è¡Œå‘½ä»¤ç»§ç»­å¤„ç†")
                    break
            
            # å¤„ç†å¤±è´¥å’Œæš‚åœçš„è‚¡ç¥¨ï¼ˆé‡è¯•ä¸€æ¬¡ï¼‰
            retry_symbols = progress_data['failed_symbols'] + progress_data['paused_symbols']
            if retry_symbols:
                logger.info(f"é‡è¯• {len(retry_symbols)} åªå¤±è´¥/æš‚åœçš„è‚¡ç¥¨...")
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©ç½‘ç»œçŠ¶æ€æ¢å¤
                time.sleep(30)
                
                retry_success = 0
                retry_symbols_copy = retry_symbols.copy()
                
                for symbol in retry_symbols_copy:
                    try:
                        updated_count = self.data_fetcher.update_stock_data_with_fixed_delay(symbol, days)
                        if updated_count > 0:
                            retry_success += 1
                            progress_data['success_count'] += 1
                            progress_data['total_records'] += updated_count
                            
                            # ä»å¤±è´¥åˆ—è¡¨ä¸­ç§»é™¤
                            if symbol in progress_data['failed_symbols']:
                                progress_data['failed_symbols'].remove(symbol)
                                progress_data['failed_count'] -= 1
                            if symbol in progress_data['paused_symbols']:
                                progress_data['paused_symbols'].remove(symbol)
                            
                            logger.info(f"  âœ… é‡è¯•æˆåŠŸ: {symbol} ({updated_count} æ¡è®°å½•)")
                        else:
                            logger.warning(f"  âŒ é‡è¯•ä»å¤±è´¥: {symbol}")
                    except Exception as e:
                        logger.error(f"  âŒ é‡è¯•å¤±è´¥: {symbol} - {e}")
                
                logger.info(f"é‡è¯•å®Œæˆï¼ŒæˆåŠŸæ¢å¤ {retry_success} åªè‚¡ç¥¨")
            
            # æœ€ç»ˆç»Ÿè®¡
            total_elapsed_time = time.time() - total_start_time
            progress_data['end_time'] = datetime.now().isoformat()
            progress_data['total_elapsed_time'] = total_elapsed_time
            
            # è·å–æœ€ç»ˆç½‘ç»œæŒ‡æ ‡
            final_metrics = self.data_fetcher.get_metrics_summary()
            progress_data['final_metrics'] = final_metrics
            
            logger.info(f"å¢å¼ºç‰ˆæ‰¹é‡æ›´æ–°å®Œæˆ!")
            logger.info(f"æ€»è‚¡ç¥¨æ•°: {total_stocks:,}")
            logger.info(f"æˆåŠŸæ›´æ–°: {progress_data['success_count']:,} åªè‚¡ç¥¨")
            logger.info(f"å¤±è´¥: {progress_data['failed_count']:,} åªè‚¡ç¥¨")
            logger.info(f"å› ç½‘ç»œæš‚åœ: {len(progress_data['paused_symbols'])} åªè‚¡ç¥¨")
            logger.info(f"æ€»è®°å½•æ•°: {progress_data['total_records']:,} æ¡")
            logger.info(f"æ€»è€—æ—¶: {total_elapsed_time/60:.1f} åˆ†é’Ÿ")
            logger.info(f"ç½‘ç»œæš‚åœæ¬¡æ•°: {progress_data['network_pauses']}")
            logger.info(f"æœ€ç»ˆç½‘ç»œçŠ¶æ€: {final_metrics['network_status']}")
            logger.info(f"æœ€ç»ˆæˆåŠŸç‡: {final_metrics['success_rate']}")
            
            if total_elapsed_time > 0:
                logger.info(f"å¹³å‡é€Ÿåº¦: {total_stocks/(total_elapsed_time/60):.1f} åªè‚¡ç¥¨/åˆ†é’Ÿ")
            
            # ä¿å­˜æœ€ç»ˆè¿›åº¦
            self.save_enhanced_progress(progress_data, progress_file)
            
            return progress_data
            
        except Exception as e:
            logger.error(f"å¢å¼ºç‰ˆæ‰¹é‡æ›´æ–°å†å²æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def save_enhanced_progress(self, progress_data: dict, progress_file: str = "data/enhanced_batch_progress.json"):
        """ä¿å­˜å¢å¼ºç‰ˆæ‰¹å¤„ç†è¿›åº¦"""
        os.makedirs(os.path.dirname(progress_file), exist_ok=True)
        
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
    
    def load_enhanced_progress(self, progress_file: str = "data/enhanced_batch_progress.json") -> dict:
        """åŠ è½½å¢å¼ºç‰ˆæ‰¹å¤„ç†è¿›åº¦"""
        if not os.path.exists(progress_file):
            return {}
        
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"åŠ è½½å¢å¼ºç‰ˆè¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def show_enhanced_progress_status(self):
        """æ˜¾ç¤ºå¢å¼ºç‰ˆè¿›åº¦çŠ¶æ€"""
        progress_file = "data/enhanced_batch_progress.json"
        progress_data = self.load_enhanced_progress(progress_file)
        
        if not progress_data:
            print("æ²¡æœ‰æ‰¾åˆ°å¢å¼ºç‰ˆè¿›åº¦æ–‡ä»¶")
            return
        
        print("\n" + "="*60)
        print("å¢å¼ºç‰ˆæ‰¹å¤„ç†è¿›åº¦çŠ¶æ€")
        print("="*60)
        
        total_stocks = progress_data.get('total_stocks', 0)
        success_count = progress_data.get('success_count', 0)
        failed_count = progress_data.get('failed_count', 0)
        paused_count = len(progress_data.get('paused_symbols', []))
        processed_count = success_count + failed_count + paused_count
        
        print(f"æ€»è‚¡ç¥¨æ•°: {total_stocks:,}")
        print(f"å·²å¤„ç†: {processed_count:,} ({processed_count/total_stocks*100:.1f}%)")
        print(f"æˆåŠŸ: {success_count:,}")
        print(f"å¤±è´¥: {failed_count:,}")
        print(f"ç½‘ç»œæš‚åœ: {paused_count:,}")
        print(f"æ€»è®°å½•æ•°: {progress_data.get('total_records', 0):,}")
        
        if 'start_time' in progress_data:
            start_time = datetime.fromisoformat(progress_data['start_time'])
            print(f"å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        if 'last_update' in progress_data:
            last_update = datetime.fromisoformat(progress_data['last_update'])
            print(f"æœ€åæ›´æ–°: {last_update.strftime('%Y-%m-%d %H:%M:%S')}")
        
        if 'network_pauses' in progress_data:
            print(f"ç½‘ç»œæš‚åœæ¬¡æ•°: {progress_data['network_pauses']}")
        
        if 'current_network_status' in progress_data:
            print(f"å½“å‰ç½‘ç»œçŠ¶æ€: {progress_data['current_network_status']}")
        
        if 'current_success_rate' in progress_data:
            print(f"å½“å‰æˆåŠŸç‡: {progress_data['current_success_rate']}")
        
        print("="*60 + "\n")
    
    def create_failed_stocks_recovery_plan(self):
        """åˆ›å»ºå¤±è´¥è‚¡ç¥¨æ¢å¤è®¡åˆ’"""
        progress_file = "data/enhanced_batch_progress.json"
        progress_data = self.load_enhanced_progress(progress_file)
        
        if not progress_data:
            print("æ²¡æœ‰æ‰¾åˆ°è¿›åº¦æ–‡ä»¶")
            return
        
        failed_symbols = progress_data.get('failed_symbols', [])
        paused_symbols = progress_data.get('paused_symbols', [])
        
        if not failed_symbols and not paused_symbols:
            print("æ²¡æœ‰éœ€è¦æ¢å¤çš„è‚¡ç¥¨")
            return
        
        recovery_plan = {
            'failed_symbols': failed_symbols,
            'paused_symbols': paused_symbols,
            'total_to_recover': len(failed_symbols) + len(paused_symbols),
            'created_time': datetime.now().isoformat(),
            'recovery_strategy': {
                'batch_size': 10,  # å°æ‰¹é‡å¤„ç†
                'delay_multiplier': 2.0,  # å¢åŠ å»¶è¿Ÿ
                'max_retries': 3
            }
        }
        
        recovery_file = "data/stock_recovery_plan.json"
        with open(recovery_file, 'w', encoding='utf-8') as f:
            json.dump(recovery_plan, f, ensure_ascii=False, indent=2)
        
        print(f"å·²åˆ›å»ºè‚¡ç¥¨æ¢å¤è®¡åˆ’: {recovery_file}")
        print(f"éœ€è¦æ¢å¤çš„è‚¡ç¥¨æ•°: {recovery_plan['total_to_recover']}")
        print(f"å¤±è´¥è‚¡ç¥¨: {len(failed_symbols)}")
        print(f"æš‚åœè‚¡ç¥¨: {len(paused_symbols)}")
        
    def test_api_connectivity(self, test_symbols: List[str] = None):
        """
        æµ‹è¯•APIè¿æ¥æ€§å’Œæ•°æ®è·å–åŠŸèƒ½
        
        Args:
            test_symbols: æµ‹è¯•ç”¨çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æµ‹è¯•è‚¡ç¥¨
        """
        print("\n" + "="*60)
        print("APIè¿æ¥æ€§æµ‹è¯•")
        print("="*60)
        
        # é»˜è®¤æµ‹è¯•è‚¡ç¥¨ä»£ç 
        if not test_symbols:
            test_symbols = ['000001', '000002']
        
        print(f"ğŸ“¡ æµ‹è¯•è‚¡ç¥¨ä»£ç : {', '.join(test_symbols)}")
        print(f"ğŸ” æµ‹è¯•é¡¹ç›®: ç½‘ç»œè¿æ¥ã€æ•°æ®è·å–ã€APIå“åº”")
        
        results = {
            'total_tested': len(test_symbols),
            'success_count': 0,
            'failed_count': 0,
            'api_status': 'unknown',
            'network_status': 'unknown',
            'test_details': []
        }
        
        try:
            # è·å–ç½‘ç»œçŠ¶æ€
            network_status = self.data_fetcher.delay_manager.get_network_status()
            results['network_status'] = network_status.value
            print(f"ğŸŒ å½“å‰ç½‘ç»œçŠ¶æ€: {network_status.value}")
            
            print("\nå¼€å§‹APIæµ‹è¯•...")
            print("-" * 40)
            
            for i, symbol in enumerate(test_symbols, 1):
                print(f"\n[{i}/{len(test_symbols)}] æµ‹è¯•è‚¡ç¥¨: {symbol}")
                
                test_detail = {
                    'symbol': symbol,
                    'success': False,
                    'records_count': 0,
                    'error': None,
                    'response_time': 0
                }
                
                try:
                    start_time = time.time()
                    
                    # è·å–APIè°ƒç”¨å‰çš„æœ€æ–°æ•°æ®æ—¥æœŸ
                    last_date_before = self.db.get_last_update_date(symbol)
                    
                    # æµ‹è¯•è·å–æœ€è¿‘1å¤©çš„æ•°æ®ï¼ˆå°è¯•è·å–ä»Šå¤©çš„æ•°æ®ï¼‰
                    updated_count = self.data_fetcher.update_stock_data_with_fixed_delay(symbol, days=1)
                    
                    response_time = time.time() - start_time
                    test_detail['response_time'] = response_time
                    
                    # è·å–APIè°ƒç”¨åçš„æœ€æ–°æ•°æ®æ—¥æœŸ
                    last_date_after = self.db.get_last_update_date(symbol)
                    
                    if updated_count >= 0:  # APIè°ƒç”¨æˆåŠŸ
                        test_detail['success'] = True
                        test_detail['records_count'] = updated_count
                        results['success_count'] += 1
                        
                        # åˆ†æAPIè°ƒç”¨ç»“æœ
                        from datetime import date
                        today = date.today().isoformat()
                        
                        if updated_count > 0:
                            print(f"  âœ… APIæˆåŠŸ - æ–°å¢ {updated_count} æ¡è®°å½• ({response_time:.2f}ç§’)")
                            print(f"  ğŸ“Š æ•°æ®æ›´æ–°: {last_date_before} â†’ {last_date_after}")
                        else:
                            print(f"  âœ… APIæˆåŠŸ - æ— æ–°æ•°æ® ({response_time:.2f}ç§’)")
                            print(f"  ğŸ“Š æœ€æ–°æ•°æ®æ—¥æœŸ: {last_date_after or 'æ— æ•°æ®'}")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ä»Šå¤©çš„æ•°æ®
                        if last_date_after == today:
                            print(f"  ğŸ¯ âœ… å·²è·å–ä»Šæ—¥æ•°æ®: {today}")
                        elif last_date_after:
                            print(f"  ğŸ¯ âš ï¸ æœ€æ–°æ•°æ®: {last_date_after} (ä»Šæ—¥: {today})")
                            print(f"      å¯èƒ½åŸå› : å¸‚åœºæœªå¼€ç›˜ã€æ•°æ®æºæœªæ›´æ–°æˆ–éäº¤æ˜“æ—¥")
                        else:
                            print(f"  ğŸ¯ âŒ æ•°æ®åº“ä¸­æ— æ­¤è‚¡ç¥¨æ•°æ®")
                    else:
                        test_detail['error'] = "APIè¿”å›è´Ÿå€¼"
                        results['failed_count'] += 1
                        print(f"  âŒ å¤±è´¥ - APIè¿”å›å¼‚å¸¸å€¼: {updated_count}")
                        
                except Exception as e:
                    test_detail['error'] = str(e)
                    results['failed_count'] += 1
                    print(f"  âŒ å¤±è´¥ - {e}")
                
                results['test_details'].append(test_detail)
                
                # çŸ­æš‚å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(1)
            
            # è®¡ç®—APIçŠ¶æ€
            success_rate = results['success_count'] / results['total_tested']
            if success_rate >= 0.8:
                results['api_status'] = 'good'
            elif success_rate >= 0.5:
                results['api_status'] = 'fair'
            else:
                results['api_status'] = 'poor'
            
            # æ˜¾ç¤ºæµ‹è¯•æ€»ç»“
            print("\n" + "="*60)
            print("APIæµ‹è¯•æ€»ç»“")
            print("="*60)
            print(f"ğŸ“Š æµ‹è¯•è‚¡ç¥¨æ•°: {results['total_tested']}")
            print(f"âœ… æˆåŠŸ: {results['success_count']}")
            print(f"âŒ å¤±è´¥: {results['failed_count']}")
            print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1%}")
            print(f"ğŸŒ ç½‘ç»œçŠ¶æ€: {results['network_status']}")
            print(f"ğŸ”Œ APIçŠ¶æ€: {results['api_status']}")
            
            # æ˜¾ç¤ºå“åº”æ—¶é—´ç»Ÿè®¡
            response_times = [detail['response_time'] for detail in results['test_details'] if detail['success']]
            if response_times:
                avg_response_time = sum(response_times) / len(response_times)
                max_response_time = max(response_times)
                min_response_time = min(response_times)
                print(f"â±ï¸ å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ç§’")
                print(f"â±ï¸ æœ€å¿«å“åº”: {min_response_time:.2f}ç§’")
                print(f"â±ï¸ æœ€æ…¢å“åº”: {max_response_time:.2f}ç§’")
            
            # ç»™å‡ºå»ºè®®
            print("\nğŸ’¡ å»ºè®®:")
            if results['api_status'] == 'good':
                print("  âœ… APIå·¥ä½œæ­£å¸¸ï¼Œå¯ä»¥è¿›è¡Œæ‰¹é‡æ•°æ®æ›´æ–°")
            elif results['api_status'] == 'fair':
                print("  âš ï¸ APIéƒ¨åˆ†æ­£å¸¸ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
            else:
                print("  âŒ APIçŠ¶æ€ä¸ä½³ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®")
                print("  ğŸ’¡ å¯ä»¥å°è¯•ä½¿ç”¨ä¼ä¸šæ¨¡å¼: --enterprise-mode")
            
            # æ˜¾ç¤ºå¤±è´¥è¯¦æƒ…
            failed_tests = [detail for detail in results['test_details'] if not detail['success']]
            if failed_tests:
                print(f"\nâŒ å¤±è´¥è¯¦æƒ…:")
                for detail in failed_tests:
                    print(f"  {detail['symbol']}: {detail['error']}")
            
            print("="*60)
            
            return results
            
        except Exception as e:
            print(f"âŒ APIæµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return results



def create_enhanced_argument_parser():
    """åˆ›å»ºå¢å¼ºç‰ˆå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="å¢å¼ºç‰ˆçŸ­çº¿é€‰è‚¡å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
å¢å¼ºç‰ˆåŠŸèƒ½:
  python enhanced_main.py --update-all-enhanced --days 60    # å¢å¼ºç‰ˆæ‰¹é‡æ›´æ–°
  python enhanced_main.py --show-progress                    # æ˜¾ç¤ºè¿›åº¦çŠ¶æ€
  python enhanced_main.py --create-recovery-plan             # åˆ›å»ºæ¢å¤è®¡åˆ’
  python enhanced_main.py --test-network                     # æµ‹è¯•ç½‘ç»œçŠ¶æ€
  python enhanced_main.py --test-api                         # æµ‹è¯•APIè¿æ¥æ€§
  python enhanced_main.py --diagnose-network                 # å®Œæ•´ç½‘ç»œè¯Šæ–­
  
ä¼ä¸šç½‘ç»œæ¨¡å¼:
  python enhanced_main.py --update-all-enhanced --enterprise-mode --days 60  # ä¼ä¸šæ¨¡å¼æ›´æ–°
  python enhanced_main.py --test-network --enterprise-mode                   # ä¼ä¸šæ¨¡å¼æµ‹è¯•

æ•°æ®åˆ·æ–°å·¥å…· (data_refresh.py):
  python data_refresh.py smart-refresh                       # æ™ºèƒ½åˆ·æ–°ï¼ˆåŸºäºæŠ¥å‘Šï¼‰
  python data_refresh.py smart-refresh --test-mode --yes     # æµ‹è¯•æ¨¡å¼æ™ºèƒ½åˆ·æ–°
  python data_refresh.py full-refresh                        # å…¨é‡æ•°æ®åˆ·æ–°
  python data_refresh.py full-refresh --max-stocks 100      # é™åˆ¶è‚¡ç¥¨æ•°é‡çš„å…¨é‡åˆ·æ–°
  python data_refresh.py cleanup                             # æ¸…ç†å¤±è´¥è‚¡ç¥¨åˆ—è¡¨
  python data_refresh.py cleanup --yes                       # è·³è¿‡ç¡®è®¤çš„æ¸…ç†æ“ä½œ
  python data_refresh.py check                               # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
  python data_refresh.py check --target-days 60             # è‡ªå®šä¹‰å¤©æ•°çš„å®Œæ•´æ€§æ£€æŸ¥
        """
    )
    
    # å¢å¼ºç‰ˆåŠŸèƒ½é€‰é¡¹
    parser.add_argument('--update-all-enhanced', action='store_true',
                       help='ä½¿ç”¨å¢å¼ºç‰ˆç®—æ³•æ›´æ–°æ‰€æœ‰è‚¡ç¥¨å†å²æ•°æ®')
    parser.add_argument('--show-progress', action='store_true',
                       help='æ˜¾ç¤ºå¢å¼ºç‰ˆæ‰¹å¤„ç†è¿›åº¦çŠ¶æ€')
    parser.add_argument('--create-recovery-plan', action='store_true',
                       help='ä¸ºå¤±è´¥çš„è‚¡ç¥¨åˆ›å»ºæ¢å¤è®¡åˆ’')
    parser.add_argument('--test-network', action='store_true',
                       help='æµ‹è¯•ç½‘ç»œçŠ¶æ€å’Œå»¶è¿Ÿç­–ç•¥')
    parser.add_argument('--diagnose-network', action='store_true',
                       help='è¿è¡Œå®Œæ•´çš„ç½‘ç»œè¯Šæ–­')
    parser.add_argument('--test-api', action='store_true',
                       help='æµ‹è¯•APIè¿æ¥æ€§å’Œæ•°æ®è·å–åŠŸèƒ½')
    parser.add_argument('--enterprise-mode', action='store_true',
                       help='å¯ç”¨ä¼ä¸šç½‘ç»œæ¨¡å¼ï¼ˆæ›´ä¿å®ˆçš„å»¶è¿Ÿå’Œé‡è¯•ç­–ç•¥ï¼‰')
    
    # å‚æ•°é€‰é¡¹
    parser.add_argument('--days', type=int, default=60,
                       help='å†å²æ•°æ®å¤©æ•° (é»˜è®¤: 60)')
    parser.add_argument('--no-resume', action='store_true',
                       help='ä¸ä½¿ç”¨æ–­ç‚¹ç»­ä¼ ï¼Œä»å¤´å¼€å§‹')
    
    return parser


def main():
    """å¢å¼ºç‰ˆä¸»å‡½æ•°"""
    parser = create_enhanced_argument_parser()
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æä¾›ä»»ä½•å‚æ•°ï¼Œæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    if len(sys.argv) == 1:
        parser.print_help()
        return
    
    try:
        # åˆå§‹åŒ–å¢å¼ºç‰ˆåº”ç”¨
        app = EnhancedStockSelectorApp(enterprise_mode=args.enterprise_mode)
        
        if args.enterprise_mode:
            print("ğŸ¢ ä¼ä¸šç½‘ç»œæ¨¡å¼å·²å¯ç”¨")
            print("   - ä½¿ç”¨æ›´ä¿å®ˆçš„å»¶è¿Ÿç­–ç•¥")
            print("   - å‡å°‘é‡è¯•æ¬¡æ•°")
            print("   - å¢åŠ è¯·æ±‚è¶…æ—¶æ—¶é—´")
            print("   - é€‚åˆä¼ä¸šé˜²ç«å¢™ç¯å¢ƒ")
        
        # æ˜¾ç¤ºè¿›åº¦çŠ¶æ€
        if args.show_progress:
            app.show_enhanced_progress_status()
            return
        
        # åˆ›å»ºæ¢å¤è®¡åˆ’
        if args.create_recovery_plan:
            app.create_failed_stocks_recovery_plan()
            return
        
        # æµ‹è¯•ç½‘ç»œçŠ¶æ€
        if args.test_network:
            print("æµ‹è¯•ç½‘ç»œçŠ¶æ€...")
            test_symbols = ['000001', '000002', '600000']
            results = app.data_fetcher.batch_update_with_monitoring(test_symbols, days=5)
            
            print("\næµ‹è¯•ç»“æœ:")
            for symbol, count in results.items():
                print(f"  {symbol}: {count} æ¡è®°å½•")
            
            print("\nç½‘ç»œæŒ‡æ ‡:")
            metrics = app.data_fetcher.get_metrics_summary()
            for key, value in metrics.items():
                print(f"  {key}: {value}")
            return
        
        # ç½‘ç»œè¯Šæ–­
        if args.diagnose_network:
            print("è¿è¡Œç½‘ç»œè¯Šæ–­...")
            try:
                from network_diagnostic import NetworkDiagnostic
                diagnostic = NetworkDiagnostic()
                diagnostic.run_full_diagnostic()
                diagnostic.generate_report()
                print("ç½‘ç»œè¯Šæ–­å®Œæˆï¼Œè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜")
            except ImportError:
                print("âŒ ç½‘ç»œè¯Šæ–­æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿ network_diagnostic.py å­˜åœ¨")
            except Exception as e:
                print(f"âŒ ç½‘ç»œè¯Šæ–­å¤±è´¥: {e}")
            return
        
        # APIè¿æ¥æ€§æµ‹è¯•
        if args.test_api:
            print("ğŸ” å¼€å§‹APIè¿æ¥æ€§æµ‹è¯•...")
            results = app.test_api_connectivity()
            return
        
        # å¢å¼ºç‰ˆæ‰¹é‡æ›´æ–°
        if args.update_all_enhanced:
            print(f"\nğŸš€ å¼€å§‹å¢å¼ºç‰ˆæ‰¹é‡æ›´æ–°æ‰€æœ‰è‚¡ç¥¨è¿‘{args.days}å¤©çš„å†å²æ•°æ®...")
            print("âœ¨ æ–°åŠŸèƒ½: åŠ¨æ€å»¶è¿Ÿã€æŒ‡æ•°é€€é¿ã€ç½‘ç»œçŠ¶æ€ç›‘æ§")
            print("âš ï¸  è¿™æ˜¯ä¸€ä¸ªé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ï¼Œæ”¯æŒæ™ºèƒ½æ–­ç‚¹ç»­ä¼ ")
            print("   å¦‚æœä¸­é€”ä¸­æ–­ï¼Œå¯ä»¥é‡æ–°è¿è¡Œç›¸åŒå‘½ä»¤ä»ä¸­æ–­å¤„ç»§ç»­")
            
            resume = not args.no_resume
            result = app.update_all_stocks_historical_data_enhanced(
                days=args.days,
                resume=resume
            )
            
            if result:
                success_count = result.get('success_count', 0)
                failed_count = result.get('failed_count', 0)
                paused_count = len(result.get('paused_symbols', []))
                total_records = result.get('total_records', 0)
                elapsed_time = result.get('total_elapsed_time', 0)
                network_pauses = result.get('network_pauses', 0)
                
                print(f"\nâœ… å¢å¼ºç‰ˆæ‰¹é‡æ›´æ–°å®Œæˆï¼")
                print(f"æˆåŠŸæ›´æ–°: {success_count:,} åªè‚¡ç¥¨")
                print(f"å¤±è´¥: {failed_count:,} åªè‚¡ç¥¨")
                print(f"ç½‘ç»œæš‚åœ: {paused_count:,} åªè‚¡ç¥¨")
                print(f"æ€»è®°å½•æ•°: {total_records:,} æ¡")
                print(f"æ€»è€—æ—¶: {elapsed_time/60:.1f} åˆ†é’Ÿ")
                print(f"ç½‘ç»œæš‚åœæ¬¡æ•°: {network_pauses}")
                
                if 'final_metrics' in result:
                    final_metrics = result['final_metrics']
                    print(f"æœ€ç»ˆç½‘ç»œçŠ¶æ€: {final_metrics['network_status']}")
                    print(f"æœ€ç»ˆæˆåŠŸç‡: {final_metrics['success_rate']}")
                
                if failed_count > 0 or paused_count > 0:
                    print(f"\nâš ï¸  æœ‰ {failed_count + paused_count} åªè‚¡ç¥¨éœ€è¦æ¢å¤")
                    print("   å¯ä»¥è¿è¡Œ --create-recovery-plan åˆ›å»ºæ¢å¤è®¡åˆ’")
                
                # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
                print("\nğŸ“Š ä½¿ç”¨ --show-progress æŸ¥çœ‹è¯¦ç»†è¿›åº¦")
            else:
                print("\nâŒ å¢å¼ºç‰ˆæ‰¹é‡æ›´æ–°å¤±è´¥ï¼")
        
        else:
            print("è¯·æŒ‡å®šè¦æ‰§è¡Œçš„æ“ä½œï¼Œä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯")
    
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        print("\næ“ä½œå·²å–æ¶ˆ")
    
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()