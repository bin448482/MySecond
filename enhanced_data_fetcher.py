"""
å¢å¼ºç‰ˆæ•°æ®è·å–æ¨¡å—
å®ç°åŠ¨æ€å»¶è¿Ÿã€æŒ‡æ•°é€€é¿ã€ç½‘ç»œçŠ¶æ€ç›‘æ§ç­‰åŠŸèƒ½
æé«˜ç½‘ç»œè¯·æ±‚çš„ç¨³å®šæ€§å’ŒæˆåŠŸç‡
"""

import akshare as ak
import pandas as pd
from datetime import datetime, date, timedelta
from typing import List, Optional, Dict, Tuple
import time
import logging
import random
import math
from database import DatabaseManager
import warnings
from dataclasses import dataclass
from enum import Enum

# å¿½ç•¥è­¦å‘Šä¿¡æ¯
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class NetworkStatus(Enum):
    """ç½‘ç»œçŠ¶æ€æšä¸¾"""
    EXCELLENT = "excellent"  # æˆåŠŸç‡ > 95%
    GOOD = "good"           # æˆåŠŸç‡ 80-95%
    POOR = "poor"           # æˆåŠŸç‡ 60-80%
    BAD = "bad"             # æˆåŠŸç‡ < 60%


@dataclass
class RequestMetrics:
    """è¯·æ±‚æŒ‡æ ‡æ•°æ®ç±»"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    total_time: float = 0.0
    last_success_time: Optional[float] = None
    consecutive_failures: int = 0
    
    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡"""
        if self.total_requests == 0:
            return 1.0
        return self.successful_requests / self.total_requests
    
    @property
    def average_response_time(self) -> float:
        """å¹³å‡å“åº”æ—¶é—´"""
        if self.successful_requests == 0:
            return 0.0
        return self.total_time / self.successful_requests


class FixedDelayManager:
    """å›ºå®šå»¶è¿Ÿç®¡ç†å™¨ - ä¸“ä¸ºä¸œæ–¹è´¢å¯ŒAPIä¼˜åŒ–"""
    
    def __init__(self,
                 min_delay: float = 0.3,
                 max_delay: float = 1.0,
                 retry_delay: float = 2.0,
                 enterprise_mode: bool = False):
        """
        åˆå§‹åŒ–å›ºå®šå»¶è¿Ÿç®¡ç†å™¨
        
        Args:
            min_delay: æœ€å°å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
            max_delay: æœ€å¤§å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
            retry_delay: é‡è¯•å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
            enterprise_mode: æ˜¯å¦å¯ç”¨ä¼ä¸šç½‘ç»œæ¨¡å¼
        """
        # ä¼ä¸šç½‘ç»œæ¨¡å¼ä½¿ç”¨æ›´ä¿å®ˆçš„å»¶è¿Ÿè®¾ç½®
        if enterprise_mode:
            self.min_delay = max(min_delay, 2.0)
            self.max_delay = max(max_delay, 5.0)
            self.retry_delay = max(retry_delay, 10.0)
            logger.info(f"å¯ç”¨ä¼ä¸šç½‘ç»œæ¨¡å¼: {self.min_delay}-{self.max_delay}ç§’å»¶è¿Ÿ")
        else:
            self.min_delay = min_delay
            self.max_delay = max_delay
            self.retry_delay = retry_delay
            logger.info(f"åˆå§‹åŒ–å›ºå®šå»¶è¿Ÿç®¡ç†å™¨: {min_delay}-{max_delay}ç§’å»¶è¿Ÿ")
        
        self.metrics = RequestMetrics()
        self.enterprise_mode = enterprise_mode
    
    def get_delay(self, is_retry: bool = False, retry_count: int = 0) -> float:
        """
        è·å–å»¶è¿Ÿæ—¶é—´
        
        Args:
            is_retry: æ˜¯å¦ä¸ºé‡è¯•è¯·æ±‚
            retry_count: é‡è¯•æ¬¡æ•°
            
        Returns:
            å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        """
        if is_retry:
            # é‡è¯•æ—¶ä½¿ç”¨å›ºå®šå»¶è¿Ÿï¼Œé¿å…è¿‡äºæ¿€è¿›
            delay = self.retry_delay * (1 + retry_count * 0.5)  # é€’å¢å»¶è¿Ÿ
        else:
            # æ­£å¸¸è¯·æ±‚ä½¿ç”¨éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚åŒæ­¥
            delay = random.uniform(self.min_delay, self.max_delay)
        
        return delay
    
    def record_request(self, success: bool, response_time: float = 0.0):
        """
        è®°å½•è¯·æ±‚ç»“æœ
        
        Args:
            success: è¯·æ±‚æ˜¯å¦æˆåŠŸ
            response_time: å“åº”æ—¶é—´
        """
        self.metrics.total_requests += 1
        
        if success:
            self.metrics.successful_requests += 1
            self.metrics.total_time += response_time
            self.metrics.last_success_time = time.time()
            self.metrics.consecutive_failures = 0
        else:
            self.metrics.failed_requests += 1
            self.metrics.consecutive_failures += 1
    
    def get_network_status(self) -> NetworkStatus:
        """è·å–å½“å‰ç½‘ç»œçŠ¶æ€"""
        success_rate = self.metrics.success_rate
        
        if success_rate > 0.95:
            return NetworkStatus.EXCELLENT
        elif success_rate > 0.80:
            return NetworkStatus.GOOD
        elif success_rate > 0.60:
            return NetworkStatus.POOR
        else:
            return NetworkStatus.BAD
    
    def should_pause(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æš‚åœè¯·æ±‚"""
        # è¿ç»­å¤±è´¥è¶…è¿‡15æ¬¡ï¼Œå»ºè®®æš‚åœï¼ˆæ¯”ä¹‹å‰æ›´å®½æ¾ï¼‰
        if self.metrics.consecutive_failures > 15:
            return True
        
        # æˆåŠŸç‡è¿‡ä½ä¸”è¯·æ±‚æ•°é‡è¶³å¤Ÿå¤šï¼Œå»ºè®®æš‚åœ
        if self.metrics.total_requests > 30 and self.metrics.success_rate < 0.2:
            return True
        
        return False


class EnhancedDataFetcher:
    """å¢å¼ºç‰ˆæ•°æ®è·å–ç±» - ä¼˜åŒ–ä¸œæ–¹è´¢å¯Œæ•°æ®æº"""
    
    def __init__(self, db_manager: DatabaseManager, enterprise_mode: bool = False):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆæ•°æ®è·å–å™¨
        
        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
            enterprise_mode: æ˜¯å¦å¯ç”¨ä¼ä¸šç½‘ç»œæ¨¡å¼
        """
        self.db = db_manager
        self.enterprise_mode = enterprise_mode
        self.delay_manager = FixedDelayManager(enterprise_mode=enterprise_mode)
        
        # é‡è¯•é…ç½® - ä¼ä¸šæ¨¡å¼ä½¿ç”¨æ›´ä¿å®ˆçš„è®¾ç½®
        if enterprise_mode:
            self.max_retry_times = 2  # å‡å°‘é‡è¯•æ¬¡æ•°
            self.retry_delays = [5, 15]  # å¢åŠ é‡è¯•å»¶è¿Ÿ
            self.request_timeout = 60  # å¢åŠ è¶…æ—¶æ—¶é—´
            self.batch_pause_threshold = 0.3  # æé«˜æš‚åœé˜ˆå€¼
            self.segment_days = 15  # å‡å°‘åˆ†æ®µå¤©æ•°
            logger.info("å¢å¼ºç‰ˆæ•°æ®è·å–å™¨åˆå§‹åŒ–å®Œæˆ - ä¼ä¸šç½‘ç»œæ¨¡å¼")
        else:
            self.max_retry_times = 3
            self.retry_delays = [2, 5, 10]
            self.request_timeout = 30
            self.batch_pause_threshold = 0.2
            self.segment_days = 30
            logger.info("å¢å¼ºç‰ˆæ•°æ®è·å–å™¨åˆå§‹åŒ–å®Œæˆ - ä½¿ç”¨ä¸œæ–¹è´¢å¯Œä¼˜å…ˆæ•°æ®æº")
    
    def get_stock_list(self) -> pd.DataFrame:
        """
        è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        Returns:
            è‚¡ç¥¨åˆ—è¡¨DataFrame
        """
        logger.info("å¼€å§‹è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
        
        for attempt in range(self.max_retry_times):
            start_time = time.time()
            
            try:
                # åº”ç”¨å»¶è¿Ÿ
                if attempt > 0:
                    delay = self.delay_manager.get_delay(is_retry=True, retry_count=attempt)
                    logger.info(f"é‡è¯•å‰ç­‰å¾… {delay:.2f} ç§’...")
                    time.sleep(delay)
                
                # è·å–è‚¡ç¥¨åˆ—è¡¨
                stock_list = ak.stock_zh_a_spot_em()
                response_time = time.time() - start_time
                
                if stock_list.empty:
                    logger.warning("è·å–åˆ°çš„è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
                    self.delay_manager.record_request(False)
                    continue
                
                # æ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ–
                stock_list = self._clean_stock_list(stock_list)
                
                # è®°å½•æˆåŠŸè¯·æ±‚
                self.delay_manager.record_request(True, response_time)
                
                logger.info(f"æˆåŠŸè·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œå…± {len(stock_list)} åªè‚¡ç¥¨")
                logger.info(f"ç½‘ç»œçŠ¶æ€: {self.delay_manager.get_network_status().value}")
                
                return stock_list
                
            except Exception as e:
                response_time = time.time() - start_time
                self.delay_manager.record_request(False, response_time)
                
                logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retry_times}): {e}")
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æš‚åœ
                if self.delay_manager.should_pause():
                    logger.warning("ç½‘ç»œçŠ¶æ€è¿‡å·®ï¼Œå»ºè®®ç¨åé‡è¯•")
                    break
        
        logger.error("è·å–è‚¡ç¥¨åˆ—è¡¨æœ€ç»ˆå¤±è´¥")
        return pd.DataFrame()
    
    def get_stock_history(self, symbol: str, period: str = "daily", 
                         start_date: Optional[str] = None, 
                         end_date: Optional[str] = None) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨å†å²æ•°æ®ï¼ˆå¸¦æ™ºèƒ½é‡è¯•ï¼‰
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            period: æ•°æ®å‘¨æœŸ
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            å†å²æ•°æ®DataFrame
        """
        # è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´
        if not end_date:
            end_date = datetime.now().strftime('%Y%m%d')
        if not start_date:
            start_date = (datetime.now() - timedelta(days=90)).strftime('%Y%m%d')
        
        for attempt in range(self.max_retry_times):
            start_time = time.time()
            
            try:
                # åº”ç”¨å»¶è¿Ÿç­–ç•¥
                if attempt > 0:
                    delay = self.delay_manager.get_delay(is_retry=True, retry_count=attempt)
                    logger.debug(f"è‚¡ç¥¨ {symbol} é‡è¯•å‰ç­‰å¾… {delay:.2f} ç§’...")
                    time.sleep(delay)
                else:
                    # æ­£å¸¸è¯·æ±‚å»¶è¿Ÿ
                    delay = self.delay_manager.get_delay()
                    time.sleep(delay)
                
                # å°è¯•å¤šä¸ªæ•°æ®æºè·å–å†å²æ•°æ®
                hist_data = self._get_stock_history_multi_source(
                    symbol=symbol,
                    period=period,
                    start_date=start_date,
                    end_date=end_date
                )
                
                response_time = time.time() - start_time
                
                if hist_data.empty:
                    logger.debug(f"è‚¡ç¥¨ {symbol} æ²¡æœ‰å†å²æ•°æ®")
                    self.delay_manager.record_request(False, response_time)
                    return pd.DataFrame()
                
                # æ•°æ®æ¸…æ´—
                hist_data = self._clean_history_data(hist_data)
                
                # è®°å½•æˆåŠŸè¯·æ±‚
                self.delay_manager.record_request(True, response_time)
                
                logger.debug(f"æˆåŠŸè·å–è‚¡ç¥¨ {symbol} å†å²æ•°æ®ï¼Œå…± {len(hist_data)} æ¡è®°å½•")
                return hist_data
                
            except Exception as e:
                response_time = time.time() - start_time
                self.delay_manager.record_request(False, response_time)
                
                # è¯¦ç»†é”™è¯¯æ—¥å¿— - æå‡åˆ°INFOçº§åˆ«ç¡®ä¿ç”¨æˆ·èƒ½çœ‹åˆ°
                import traceback
                logger.info(f"è‚¡ç¥¨ {symbol} è·å–æ•°æ®å¼‚å¸¸: {type(e).__name__}: {str(e)}")
                logger.info(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                
                # æ‰“å°åˆ°æ§åˆ¶å°ç¡®ä¿ç”¨æˆ·èƒ½çœ‹åˆ°
                print(f"âŒ è‚¡ç¥¨ {symbol} æ•°æ®è·å–å¤±è´¥: {e}")
                print(f"ğŸ” é”™è¯¯ç±»å‹: {type(e).__name__}")
                
                # æ ¹æ®é”™è¯¯ç±»å‹å†³å®šæ˜¯å¦ç»§ç»­é‡è¯•
                if self._is_permanent_error(e):
                    logger.debug(f"è‚¡ç¥¨ {symbol} é‡åˆ°æ°¸ä¹…æ€§é”™è¯¯ï¼Œåœæ­¢é‡è¯•: {e}")
                    break
                
                logger.debug(f"è·å–è‚¡ç¥¨ {symbol} å†å²æ•°æ®å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retry_times}): {e}")
                
                # æ£€æŸ¥ç½‘ç»œçŠ¶æ€
                if self.delay_manager.should_pause():
                    logger.warning(f"ç½‘ç»œçŠ¶æ€è¿‡å·®ï¼Œè·³è¿‡è‚¡ç¥¨ {symbol}")
                    break
        
        logger.debug(f"è‚¡ç¥¨ {symbol} å†å²æ•°æ®è·å–æœ€ç»ˆå¤±è´¥")
        return pd.DataFrame()
    
    def _is_permanent_error(self, error: Exception) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºæ°¸ä¹…æ€§é”™è¯¯ï¼ˆä¸éœ€è¦é‡è¯•ï¼‰
        
        Args:
            error: å¼‚å¸¸å¯¹è±¡
            
        Returns:
            æ˜¯å¦ä¸ºæ°¸ä¹…æ€§é”™è¯¯
        """
        error_str = str(error).lower()
        
        # å¸¸è§çš„æ°¸ä¹…æ€§é”™è¯¯
        permanent_errors = [
            'not found',
            '404',
            'invalid symbol',
            'delisted',
            'suspended'
        ]
        
        return any(pe in error_str for pe in permanent_errors)
    
    def update_stock_data_with_fixed_delay(self, symbol: str, days: int = 60) -> int:
        """
        ä½¿ç”¨å›ºå®šå»¶è¿Ÿæ›´æ–°å•åªè‚¡ç¥¨æ•°æ® - æ”¯æŒæ•°æ®åˆ†æ®µè·å–
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            days: è·å–å¤©æ•°
            
        Returns:
            æ›´æ–°çš„è®°å½•æ•°
        """
        try:
            # æ£€æŸ¥æ•°æ®åº“ä¸­æœ€åæ›´æ–°æ—¥æœŸ
            last_date = self.db.get_last_update_date(symbol)
            
            # ç¡®å®šå¼€å§‹æ—¥æœŸ
            if last_date:
                start_date = (datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y%m%d')
            else:
                start_date = (datetime.now() - timedelta(days=days)).strftime('%Y%m%d')
            
            end_date = datetime.now().strftime('%Y%m%d')
            
            # å¦‚æœå¼€å§‹æ—¥æœŸå¤§äºç­‰äºç»“æŸæ—¥æœŸï¼Œè¯´æ˜æ•°æ®å·²æ˜¯æœ€æ–°
            if start_date >= end_date:
                logger.debug(f"è‚¡ç¥¨ {symbol} æ•°æ®å·²æ˜¯æœ€æ–°")
                return 0
            
            # è®¡ç®—æ—¥æœŸå·®ï¼Œå†³å®šæ˜¯å¦éœ€è¦åˆ†æ®µè·å–
            start_dt = datetime.strptime(start_date, '%Y%m%d')
            end_dt = datetime.strptime(end_date, '%Y%m%d')
            date_diff = (end_dt - start_dt).days
            
            total_records = 0
            
            if date_diff > self.segment_days:
                # éœ€è¦åˆ†æ®µè·å–
                logger.debug(f"è‚¡ç¥¨ {symbol} éœ€è¦åˆ†æ®µè·å–æ•°æ®ï¼Œæ€»å¤©æ•°: {date_diff}")
                
                # åˆ†æˆä¸¤æ®µ
                mid_date = start_dt + timedelta(days=self.segment_days)
                mid_date_str = mid_date.strftime('%Y%m%d')
                
                # è·å–ç¬¬ä¸€æ®µæ•°æ®
                logger.debug(f"è·å–ç¬¬ä¸€æ®µæ•°æ®: {start_date} åˆ° {mid_date_str}")
                hist_data1 = self.get_stock_history(symbol, start_date=start_date, end_date=mid_date_str)
                if not hist_data1.empty:
                    total_records += self.db.insert_daily_data(symbol, hist_data1)
                
                # å»¶è¿Ÿåè·å–ç¬¬äºŒæ®µæ•°æ®
                delay = self.delay_manager.get_delay()
                logger.debug(f"åˆ†æ®µé—´å»¶è¿Ÿ {delay:.2f} ç§’")
                time.sleep(delay)
                
                # è·å–ç¬¬äºŒæ®µæ•°æ®
                second_start = (mid_date + timedelta(days=1)).strftime('%Y%m%d')
                logger.debug(f"è·å–ç¬¬äºŒæ®µæ•°æ®: {second_start} åˆ° {end_date}")
                hist_data2 = self.get_stock_history(symbol, start_date=second_start, end_date=end_date)
                if not hist_data2.empty:
                    total_records += self.db.insert_daily_data(symbol, hist_data2)
                
            else:
                # å•æ¬¡è·å–
                hist_data = self.get_stock_history(symbol, start_date=start_date, end_date=end_date)
                if not hist_data.empty:
                    total_records = self.db.insert_daily_data(symbol, hist_data)
            
            return total_records
            
        except Exception as e:
            import traceback
            logger.error(f"æ›´æ–°è‚¡ç¥¨ {symbol} æ•°æ®å¤±è´¥: {type(e).__name__}: {str(e)}")
            logger.error(f"è¯¦ç»†é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return 0
    
    # ä¿æŒå‘åå…¼å®¹æ€§
    def update_stock_data_with_adaptive_delay(self, symbol: str, days: int = 60) -> int:
        """å‘åå…¼å®¹æ–¹æ³•"""
        return self.update_stock_data_with_fixed_delay(symbol, days)
    
    def batch_update_with_monitoring(self, symbols: Optional[List[str]] = None, 
                                   days: int = 60, max_stocks: int = 100) -> Dict[str, int]:
        """
        å¸¦ç›‘æ§çš„æ‰¹é‡æ›´æ–°è‚¡ç¥¨æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            days: è·å–å¤©æ•°
            max_stocks: æœ€å¤§å¤„ç†è‚¡ç¥¨æ•°é‡
            
        Returns:
            æ›´æ–°ç»“æœå­—å…¸
        """
        if symbols is None:
            stock_list = self.db.get_stock_list()
            if stock_list.empty:
                logger.warning("æ•°æ®åº“ä¸­æ²¡æœ‰è‚¡ç¥¨åˆ—è¡¨ï¼Œè¯·å…ˆæ›´æ–°è‚¡ç¥¨åˆ—è¡¨")
                return {}
            symbols = stock_list['symbol'].tolist()[:max_stocks]
        
        results = {}
        total_stocks = len(symbols)
        
        logger.info(f"å¼€å§‹æ‰¹é‡æ›´æ–° {total_stocks} åªè‚¡ç¥¨çš„å†å²æ•°æ®...")
        logger.info(f"åˆå§‹ç½‘ç»œçŠ¶æ€: {self.delay_manager.get_network_status().value}")
        
        for i, symbol in enumerate(symbols, 1):
            try:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æš‚åœ
                if self.delay_manager.should_pause():
                    logger.warning(f"ç½‘ç»œçŠ¶æ€è¿‡å·®ï¼Œæš‚åœæ‰¹å¤„ç†ã€‚å·²å¤„ç† {i-1}/{total_stocks}")
                    break
                
                logger.info(f"æ­£åœ¨æ›´æ–° {symbol} ({i}/{total_stocks})")
                updated_count = self.update_stock_data_with_fixed_delay(symbol, days)
                results[symbol] = updated_count
                
                # æ¯å¤„ç†50åªè‚¡ç¥¨æ˜¾ç¤ºä¸€æ¬¡çŠ¶æ€
                if i % 50 == 0:
                    status = self.delay_manager.get_network_status()
                    success_rate = self.delay_manager.metrics.success_rate
                    logger.info(f"è¿›åº¦: {i}/{total_stocks}, ç½‘ç»œçŠ¶æ€: {status.value}, æˆåŠŸç‡: {success_rate:.2%}")
                
            except Exception as e:
                logger.error(f"æ›´æ–°è‚¡ç¥¨ {symbol} å¤±è´¥: {e}")
                results[symbol] = 0
        
        # ç»Ÿè®¡ç»“æœ
        total_updated = sum(results.values())
        success_count = sum(1 for count in results.values() if count > 0)
        final_success_rate = self.delay_manager.metrics.success_rate
        
        logger.info(f"æ‰¹é‡æ›´æ–°å®Œæˆ: æˆåŠŸ {success_count}/{len(results)} åªè‚¡ç¥¨")
        logger.info(f"å…±æ›´æ–° {total_updated} æ¡è®°å½•ï¼Œæœ€ç»ˆæˆåŠŸç‡: {final_success_rate:.2%}")
        
        return results
    
    def _clean_stock_list(self, stock_list: pd.DataFrame) -> pd.DataFrame:
        """æ¸…æ´—è‚¡ç¥¨åˆ—è¡¨æ•°æ®"""
        # é‡å‘½ååˆ—
        column_mapping = {
            'ä»£ç ': 'symbol',
            'åç§°': 'name',
            'æœ€æ–°ä»·': 'price',
            'æ¶¨è·Œå¹…': 'change_pct',
            'æ¶¨è·Œé¢': 'change_amount',
            'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'amount',
            'æŒ¯å¹…': 'amplitude',
            'æœ€é«˜': 'high',
            'æœ€ä½': 'low',
            'ä»Šå¼€': 'open',
            'æ˜¨æ”¶': 'pre_close',
            'æ¢æ‰‹ç‡': 'turnover_rate',
            'å¸‚ç›ˆç‡-åŠ¨æ€': 'pe_ratio',
            'å¸‚å‡€ç‡': 'pb_ratio',
            'æ€»å¸‚å€¼': 'total_market_cap',
            'æµé€šå¸‚å€¼': 'circulating_market_cap'
        }
        
        # é€‰æ‹©éœ€è¦çš„åˆ—å¹¶é‡å‘½å
        available_columns = [col for col in column_mapping.keys() if col in stock_list.columns]
        stock_list = stock_list[available_columns].copy()
        stock_list.rename(columns=column_mapping, inplace=True)
        
        # è¿‡æ»¤æ‰STã€*STç­‰ç‰¹æ®Šè‚¡ç¥¨
        if 'name' in stock_list.columns:
            stock_list = stock_list[~stock_list['name'].str.contains('ST|é€€', na=False)]
        
        # è¿‡æ»¤æ‰ä»·æ ¼å¼‚å¸¸çš„è‚¡ç¥¨
        if 'price' in stock_list.columns:
            stock_list = stock_list[
                (stock_list['price'] > 1) & 
                (stock_list['price'] < 1000)
            ]
        
        # æ·»åŠ å¸‚åœºä¿¡æ¯
        if 'symbol' in stock_list.columns:
            stock_list['market'] = stock_list['symbol'].apply(self._get_market_info)
        
        # é‡ç½®ç´¢å¼•
        stock_list.reset_index(drop=True, inplace=True)
        
        return stock_list
    
    def _get_market_info(self, symbol: str) -> str:
        """æ ¹æ®è‚¡ç¥¨ä»£ç åˆ¤æ–­æ‰€å±å¸‚åœº"""
        if symbol.startswith('00') or symbol.startswith('30'):
            return 'æ·±åœ³'
        elif symbol.startswith('60') or symbol.startswith('68'):
            return 'ä¸Šæµ·'
        else:
            return 'å…¶ä»–'
    
    def _clean_history_data(self, hist_data: pd.DataFrame) -> pd.DataFrame:
        """æ¸…æ´—å†å²æ•°æ®"""
        # é‡å‘½ååˆ—
        column_mapping = {
            'æ—¥æœŸ': 'date',
            'å¼€ç›˜': 'open',
            'æ”¶ç›˜': 'close',
            'æœ€é«˜': 'high',
            'æœ€ä½': 'low',
            'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'amount',
            'æŒ¯å¹…': 'amplitude',
            'æ¶¨è·Œå¹…': 'change_pct',
            'æ¶¨è·Œé¢': 'change_amount',
            'æ¢æ‰‹ç‡': 'turnover_rate'
        }
        
        # é€‰æ‹©éœ€è¦çš„åˆ—å¹¶é‡å‘½å
        available_columns = [col for col in column_mapping.keys() if col in hist_data.columns]
        hist_data = hist_data[available_columns].copy()
        hist_data.rename(columns=column_mapping, inplace=True)
        
        # æ•°æ®ç±»å‹è½¬æ¢
        if 'date' in hist_data.columns:
            hist_data['date'] = pd.to_datetime(hist_data['date']).dt.strftime('%Y-%m-%d')
        
        # æ•°å€¼åˆ—è½¬æ¢
        numeric_columns = ['open', 'close', 'high', 'low', 'volume', 'amount', 'turnover_rate']
        for col in numeric_columns:
            if col in hist_data.columns:
                hist_data[col] = pd.to_numeric(hist_data[col], errors='coerce')
        
        # å»é™¤ç©ºå€¼è¡Œ
        hist_data.dropna(subset=['date', 'close'], inplace=True)
        
        # æŒ‰æ—¥æœŸæ’åº
        hist_data.sort_values('date', inplace=True)
        hist_data.reset_index(drop=True, inplace=True)
        
        return hist_data
    
    def _get_stock_history_multi_source(self, symbol: str, period: str = "daily",
                                      start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """
        ä½¿ç”¨å¤šä¸ªæ•°æ®æºè·å–è‚¡ç¥¨å†å²æ•°æ® - ä¸œæ–¹è´¢å¯Œä¼˜å…ˆ
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            period: æ•°æ®å‘¨æœŸ
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            å†å²æ•°æ®DataFrame
        """
        # é‡æ–°æ’åºæ•°æ®æºï¼Œä¸œæ–¹è´¢å¯Œä¼˜å…ˆ
        data_sources = [
            self._get_from_eastmoney, # ä¸œæ–¹è´¢å¯Œ - ä¸»è¦æ•°æ®æº
            self._get_from_simple,    # ç®€åŒ–ç‰ˆæœ¬ - å¤‡ç”¨
            self._get_from_tencent    # è…¾è®¯æ•°æ®æº - æœ€åå¤‡ç”¨
        ]
        
        for i, get_data_func in enumerate(data_sources):
            try:
                logger.debug(f"å°è¯•æ•°æ®æº {i+1}: {get_data_func.__name__}")
                hist_data = get_data_func(symbol, period, start_date, end_date)
                
                if not hist_data.empty:
                    logger.debug(f"æ•°æ®æº {i+1} æˆåŠŸè·å– {len(hist_data)} æ¡è®°å½•")
                    return hist_data
                else:
                    logger.debug(f"æ•°æ®æº {i+1} è¿”å›ç©ºæ•°æ®")
                    
            except Exception as e:
                logger.debug(f"æ•°æ®æº {i+1} å¤±è´¥: {e}")
                continue
        
        logger.warning(f"æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œè‚¡ç¥¨ {symbol}")
        return pd.DataFrame()
    
    def _get_from_tencent(self, symbol: str, period: str, start_date: str, end_date: str) -> pd.DataFrame:
        """ä»è…¾è®¯æ•°æ®æºè·å–æ•°æ®"""
        try:
            print(f"ğŸ”„ å°è¯•è…¾è®¯æ•°æ®æº: {symbol}")
            
            # ä½¿ç”¨akshareçš„è…¾è®¯æ•°æ®æº
            hist_data = ak.stock_zh_a_hist_tx(symbol=symbol)
            
            if not hist_data.empty:
                # ç¡®ä¿æœ‰æ—¥æœŸåˆ—
                if 'date' in hist_data.columns:
                    # è¿‡æ»¤æ—¥æœŸèŒƒå›´
                    hist_data['date'] = pd.to_datetime(hist_data['date'])
                    start_dt = pd.to_datetime(start_date, format='%Y%m%d')
                    end_dt = pd.to_datetime(end_date, format='%Y%m%d')
                    
                    hist_data = hist_data[
                        (hist_data['date'] >= start_dt) &
                        (hist_data['date'] <= end_dt)
                    ]
                    
                    # è½¬æ¢æ—¥æœŸæ ¼å¼
                    hist_data['date'] = hist_data['date'].dt.strftime('%Y-%m-%d')
                
                print(f"âœ… è…¾è®¯æ•°æ®æºæˆåŠŸ: {len(hist_data)} æ¡è®°å½•")
            else:
                print(f"âš ï¸ è…¾è®¯æ•°æ®æºè¿”å›ç©ºæ•°æ®")
                
            return hist_data
            
        except Exception as e:
            print(f"âŒ è…¾è®¯æ•°æ®æºå¤±è´¥: {e}")
            logger.debug(f"è…¾è®¯æ•°æ®æºå¼‚å¸¸: {e}")
            return pd.DataFrame()
    
    def _get_from_simple(self, symbol: str, period: str, start_date: str, end_date: str) -> pd.DataFrame:
        """ç®€åŒ–ç‰ˆæ•°æ®è·å– - åªè·å–æœ€è¿‘çš„æ•°æ®"""
        try:
            print(f"ğŸ”„ å°è¯•ç®€åŒ–æ•°æ®æº: {symbol}")
            
            # å°è¯•è·å–æœ€è¿‘30å¤©çš„æ•°æ®ï¼Œä¸æŒ‡å®šå…·ä½“æ—¥æœŸèŒƒå›´
            from datetime import datetime, timedelta
            recent_start = (datetime.now() - timedelta(days=30)).strftime('%Y%m%d')
            recent_end = datetime.now().strftime('%Y%m%d')
            
            hist_data = ak.stock_zh_a_hist(
                symbol=symbol,
                period="daily",
                start_date=recent_start,
                end_date=recent_end,
                adjust="qfq"
            )
            
            # å¦‚æœæˆåŠŸè·å–åˆ°æ•°æ®ï¼Œå†è¿‡æ»¤åˆ°ç”¨æˆ·è¦æ±‚çš„æ—¥æœŸèŒƒå›´
            if not hist_data.empty and 'date' in hist_data.columns:
                hist_data['date'] = pd.to_datetime(hist_data['date'])
                start_dt = pd.to_datetime(start_date, format='%Y%m%d')
                end_dt = pd.to_datetime(end_date, format='%Y%m%d')
                
                hist_data = hist_data[
                    (hist_data['date'] >= start_dt) &
                    (hist_data['date'] <= end_dt)
                ]
                
                # è½¬æ¢æ—¥æœŸæ ¼å¼
                hist_data['date'] = hist_data['date'].dt.strftime('%Y-%m-%d')
                
                print(f"âœ… ç®€åŒ–æ•°æ®æºæˆåŠŸ: {len(hist_data)} æ¡è®°å½•")
            else:
                print(f"âš ï¸ ç®€åŒ–æ•°æ®æºè¿”å›ç©ºæ•°æ®")
            
            return hist_data
            
        except Exception as e:
            print(f"âŒ ç®€åŒ–æ•°æ®æºå¤±è´¥: {e}")
            logger.debug(f"ç®€åŒ–æ•°æ®æºå¼‚å¸¸: {e}")
            return pd.DataFrame()
    
    def _get_from_eastmoney(self, symbol: str, period: str, start_date: str, end_date: str) -> pd.DataFrame:
        """ä»ä¸œæ–¹è´¢å¯Œè·å–æ•°æ®ï¼ˆåŸå§‹æ–¹æ³•ï¼‰"""
        try:
            print(f"ğŸ”„ å°è¯•ä¸œæ–¹è´¢å¯Œæ•°æ®æº: {symbol} ({start_date} åˆ° {end_date})")
            
            # åŸå§‹çš„ä¸œæ–¹è´¢å¯Œæ•°æ®æº
            hist_data = ak.stock_zh_a_hist(
                symbol=symbol,
                period=period,
                start_date=start_date,
                end_date=end_date,
                adjust="qfq"
            )
            
            if not hist_data.empty:
                print(f"âœ… ä¸œæ–¹è´¢å¯Œæ•°æ®æºæˆåŠŸ: {len(hist_data)} æ¡è®°å½•")
            else:
                print(f"âš ï¸ ä¸œæ–¹è´¢å¯Œæ•°æ®æºè¿”å›ç©ºæ•°æ®")
                
            return hist_data
            
        except Exception as e:
            print(f"âŒ ä¸œæ–¹è´¢å¯Œæ•°æ®æºå¤±è´¥: {e}")
            logger.debug(f"ä¸œæ–¹è´¢å¯Œæ•°æ®æºå¼‚å¸¸: {e}")
            return pd.DataFrame()
    
    def get_metrics_summary(self) -> Dict[str, any]:
        """è·å–è¯·æ±‚æŒ‡æ ‡æ‘˜è¦"""
        metrics = self.delay_manager.metrics
        return {
            'total_requests': metrics.total_requests,
            'success_rate': f"{metrics.success_rate:.2%}",
            'average_response_time': f"{metrics.average_response_time:.2f}s",
            'network_status': self.delay_manager.get_network_status().value,
            'consecutive_failures': metrics.consecutive_failures,
            'delay_range': f"{self.delay_manager.min_delay:.1f}-{self.delay_manager.max_delay:.1f}s"
        }
    
    def get_today_stock_data(self, symbol: str) -> pd.DataFrame:
        """
        ç›´æ¥è·å–ä»Šå¤©çš„è‚¡ç¥¨æ•°æ®ï¼ˆç”¨äºAPIè¿æ¥æ€§æµ‹è¯•ï¼‰
        å¦‚æœä»Šå¤©æ²¡æœ‰æ•°æ®åˆ™è¿”å›ç©ºDataFrame
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            
        Returns:
            ä»Šå¤©çš„è‚¡ç¥¨æ•°æ®DataFrameï¼Œå¦‚æœä»Šå¤©æ²¡æœ‰æ•°æ®åˆ™è¿”å›ç©º
        """
        from datetime import date
        today = date.today().strftime('%Y%m%d')
        
        logger.info(f"ç›´æ¥è·å–è‚¡ç¥¨ {symbol} ä»Šæ—¥æ•°æ®: {today}")
        
        for attempt in range(self.max_retry_times):
            start_time = time.time()
            
            try:
                # åº”ç”¨å»¶è¿Ÿç­–ç•¥
                if attempt > 0:
                    delay = self.delay_manager.get_delay(is_retry=True, retry_count=attempt)
                    logger.debug(f"è‚¡ç¥¨ {symbol} é‡è¯•å‰ç­‰å¾… {delay:.2f} ç§’...")
                    time.sleep(delay)
                else:
                    # æ­£å¸¸è¯·æ±‚å»¶è¿Ÿ
                    delay = self.delay_manager.get_delay()
                    time.sleep(delay)
                
                # ç›´æ¥è°ƒç”¨akshareè·å–ä»Šå¤©çš„æ•°æ®
                print(f"ğŸ”„ ç›´æ¥è·å–ä»Šæ—¥æ•°æ®: {symbol} ({today})")
                
                # åªè·å–ä»Šå¤©çš„æ•°æ®
                hist_data = ak.stock_zh_a_hist(
                    symbol=symbol,
                    period="daily",
                    start_date=today,
                    end_date=today,
                    adjust="qfq"
                )
                
                response_time = time.time() - start_time
                
                # æ•°æ®æ¸…æ´—
                if not hist_data.empty:
                    hist_data = self._clean_history_data(hist_data)
                    print(f"âœ… è·å–ä»Šæ—¥æ•°æ®æˆåŠŸ: {len(hist_data)} æ¡è®°å½•")
                else:
                    print(f"âš ï¸ ä»Šæ—¥æ— æ•°æ®ï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥æˆ–æ•°æ®æœªæ›´æ–°ï¼‰")
                
                # è®°å½•æˆåŠŸè¯·æ±‚ï¼ˆå³ä½¿è¿”å›ç©ºæ•°æ®ï¼ŒAPIè°ƒç”¨ä¹Ÿæ˜¯æˆåŠŸçš„ï¼‰
                self.delay_manager.record_request(True, response_time)
                
                return hist_data
                
            except Exception as e:
                response_time = time.time() - start_time
                self.delay_manager.record_request(False, response_time)
                
                print(f"âŒ è·å–å¤±è´¥: {e}")
                logger.debug(f"è‚¡ç¥¨ {symbol} è·å–ä»Šæ—¥æ•°æ®å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retry_times}): {e}")
                
                # æ ¹æ®é”™è¯¯ç±»å‹å†³å®šæ˜¯å¦ç»§ç»­é‡è¯•
                if self._is_permanent_error(e):
                    logger.debug(f"è‚¡ç¥¨ {symbol} é‡åˆ°æ°¸ä¹…æ€§é”™è¯¯ï¼Œåœæ­¢é‡è¯•: {e}")
                    break
                
                # æ£€æŸ¥ç½‘ç»œçŠ¶æ€
                if self.delay_manager.should_pause():
                    logger.warning(f"ç½‘ç»œçŠ¶æ€è¿‡å·®ï¼Œè·³è¿‡è‚¡ç¥¨ {symbol}")
                    break
        
        logger.debug(f"è‚¡ç¥¨ {symbol} ä»Šæ—¥æ•°æ®è·å–æœ€ç»ˆå¤±è´¥")
        return pd.DataFrame()


if __name__ == "__main__":
    """æµ‹è¯•å¢å¼ºç‰ˆæ•°æ®è·å–åŠŸèƒ½"""
    from database import DatabaseManager
    
    # åˆå§‹åŒ–
    db = DatabaseManager()
    fetcher = EnhancedDataFetcher(db)
    
    # æµ‹è¯•è·å–è‚¡ç¥¨åˆ—è¡¨
    print("æµ‹è¯•è·å–è‚¡ç¥¨åˆ—è¡¨...")
    stock_count = len(fetcher.get_stock_list())
    print(f"è·å–è‚¡ç¥¨æ•°é‡: {stock_count}")
    
    # æµ‹è¯•è·å–å†å²æ•°æ®
    print("\næµ‹è¯•è·å–å†å²æ•°æ®...")
    test_symbols = ['000001', '000002', '600000']
    results = fetcher.batch_update_with_monitoring(test_symbols, days=30)
    
    for symbol, count in results.items():
        print(f"  {symbol}: {count} æ¡è®°å½•")
    
    # æ˜¾ç¤ºæŒ‡æ ‡æ‘˜è¦
    print("\nè¯·æ±‚æŒ‡æ ‡æ‘˜è¦:")
    summary = fetcher.get_metrics_summary()
    for key, value in summary.items():
        print(f"  {key}: {value}")